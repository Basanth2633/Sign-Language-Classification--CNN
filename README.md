This project involves building a deep learning model to classify American Sign Language (ASL) gestures using the Sign Language MNIST dataset. Grayscale images (28×28) were preprocessed and augmented with Keras’ ImageDataGenerator for improved model robustness. A custom CNN with two convolutional layers, pooling, and dense layers was implemented and trained for 30 epochs using the Adam optimizer and sparse categorical cross-entropy. Visualization techniques ensured data quality and balanced class distribution throughout the process.
